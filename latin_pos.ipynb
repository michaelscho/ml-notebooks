{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a1e5f3a4c0b74252",
      "metadata": {},
      "source": [
        "# POS tagging Latin with Flair contextual string embeddings + trained tagger\n",
        "\n",
        "This notebook shows how to use:\n",
        "\n",
        "- Contextual string embeddings (Flair LM):\n",
        "  - `mschonhardt/latin-legal-forward`\n",
        "  - `mschonhardt/latin-legal-backward`\n",
        "- POS tagger trained on top of those embeddings:\n",
        "  - `mschonhardt/latin-pos-tagger`\n",
        "\n",
        "For POS tagging you usually only need to load the **tagger** (`SequenceTagger.load(...)`), because it already contains/uses its base embeddings. Here, they are loaded for illustrative purposes. Loading the two LM embeddings separately is still useful if you want to (a) inspect/verify embeddings, or (b) reuse them for other downstream tasks.\n",
        "Model can be found on [Hugging Face](https://huggingface.co/mschonhardt/latin-pos-tagger) and [Zenodo](https://doi.org/10.5281/zenodo.18631267).\n",
        "\n",
        "\n",
        "![](https://zenodo.org/badge/DOI/10.5281/zenodo.18631267.svg)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b3e7c8b0e8c14c6c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If needed, install dependencies\n",
        "# !pip install -U flair torch pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b67c9d51f6d74203",
      "metadata": {},
      "source": [
        "## 1) Setup\n",
        "Select device, import libraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b0e2f2a10f44b9d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flair.device = cuda\n",
            "CUDA device: NVIDIA GeForce RTX 3060\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import flair\n",
        "\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# Device selection\n",
        "flair.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"flair.device =\", flair.device)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c72ee7a8ad8a4f3b",
      "metadata": {},
      "source": [
        "## 2) Load your legal Latin Flair embeddings and stack them\n",
        "This is the bidirectional setup (forward + backward) for downstream sequence tagging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9e2d42b5f5d34b93",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StackedEmbeddings [0-/home/micha/.cache/huggingface/hub/models--mschonhardt--latin-legal-forward/snapshots/8bea03e437de9ad7da812d6d686ad1fd1d1b1d0c/latin-legal-forward.pt,1-/home/micha/.cache/huggingface/hub/models--mschonhardt--latin-legal-backward/snapshots/d56792215e4f59843b2a08a5804068df749cbaaf/latin-legal-backward.pt]\n"
          ]
        }
      ],
      "source": [
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Download the actual model files from Hugging Face\n",
        "forward_path = hf_hub_download(repo_id=\"mschonhardt/latin-legal-forward\", filename=\"latin-legal-forward.pt\")\n",
        "backward_path = hf_hub_download(repo_id=\"mschonhardt/latin-legal-backward\", filename=\"latin-legal-backward.pt\")\n",
        "\n",
        "# Load them using the local paths\n",
        "forward_embeddings = FlairEmbeddings(forward_path)\n",
        "backward_embeddings = FlairEmbeddings(backward_path)\n",
        "\n",
        "# Stack as usual\n",
        "stacked_embeddings = StackedEmbeddings([forward_embeddings, backward_embeddings])\n",
        "print(stacked_embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5e0bba2d3f94c0a",
      "metadata": {},
      "source": [
        "## 3) (Optional) Embed a sentence to verify embeddings work\n",
        "This does *not* do POS tagging yet; it just computes contextual embeddings for each token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e0b2f4d7e4524f36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In \t torch.Size([4096])\n",
            "nomine \t torch.Size([4096])\n",
            "sanctae \t torch.Size([4096])\n",
            "et \t torch.Size([4096])\n",
            "individuae \t torch.Size([4096])\n",
            "trinitatis \t torch.Size([4096])\n",
            ". \t torch.Size([4096])\n"
          ]
        }
      ],
      "source": [
        "example_text = \"In nomine sanctae et individuae trinitatis .\"\n",
        "sent = Sentence(example_text)\n",
        "\n",
        "stacked_embeddings.embed(sent)\n",
        "\n",
        "# Each token now has an embedding vector. We'll print token texts + embedding dimensionality.\n",
        "for token in sent:\n",
        "    emb = token.embedding\n",
        "    print(token.text, \"\\t\", emb.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2f7c80e2c1b4a7b",
      "metadata": {},
      "source": [
        "## 4) Load POS tagger (trained on those embeddings)\n",
        "For simple POS tagging, this is usually all you need.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b0bb4dd62c124ca7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34ad74d3c3b64eff81779844c83880ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "best-model.pt:   0%|          | 0.00/752M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026-02-14 12:04:39,474 SequenceTagger predicts: Dictionary with 17 tags: ADV, CCONJ, ADJ, NOUN, VERB, ADP, PUNCT, NUM, PRON, PROPN, FM, PART, ORD, ITJ, X, <START>, <STOP>\n",
            "SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (encoder): Embedding(333, 200)\n",
            "        (rnn): LSTM(200, 2048, num_layers=2, dropout=0.1)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.1, inplace=False)\n",
            "        (encoder): Embedding(333, 200)\n",
            "        (rnn): LSTM(200, 2048, num_layers=2, dropout=0.1)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (word_dropout): WordDropout(p=0.1)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (rnn): LSTM(4096, 1024, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (linear): Linear(in_features=2048, out_features=17, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\n",
            "\n",
            "Tagger embeddings:\n",
            "StackedEmbeddings [0-/home/schonhardt/.cache/huggingface/hub/models--mschonhardt--latin-legal-forward/snapshots/8bea03e437de9ad7da812d6d686ad1fd1d1b1d0c/latin-legal-forward.pt,1-/home/schonhardt/.cache/huggingface/hub/models--mschonhardt--latin-legal-backward/snapshots/d56792215e4f59843b2a08a5804068df749cbaaf/latin-legal-backward.pt]\n"
          ]
        }
      ],
      "source": [
        "POS_TAGGER_ID = \"mschonhardt/latin-pos-tagger\"\n",
        "\n",
        "# Download the specific model file from the repo\n",
        "# Note: In this repo, the relevant file is named 'best-model.pt'\n",
        "tagger_path = hf_hub_download(repo_id=POS_TAGGER_ID, filename=\"best-model.pt\")\n",
        "\n",
        "# Load the tagger using the local path\n",
        "tagger = SequenceTagger.load(tagger_path)\n",
        "\n",
        "print(tagger)\n",
        "\n",
        "# Inspect embeddings\n",
        "try:\n",
        "    print(\"\\nTagger embeddings:\")\n",
        "    print(tagger.embeddings)\n",
        "except Exception as e:\n",
        "    print(\"Could not print tagger.embeddings:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95f7c1a2b5d45da",
      "metadata": {},
      "source": [
        "## 5) POS-tag a single sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf2b0c727c3f4e86",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "      <th>label_type</th>\n",
              "      <th>pos</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Arma</td>\n",
              "      <td>pos</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>0.5548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>virumque</td>\n",
              "      <td>pos</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>0.9616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cano</td>\n",
              "      <td>pos</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>0.4905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>,</td>\n",
              "      <td>pos</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Troiae</td>\n",
              "      <td>pos</td>\n",
              "      <td>PROPN</td>\n",
              "      <td>0.9718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>qui</td>\n",
              "      <td>pos</td>\n",
              "      <td>PRON</td>\n",
              "      <td>0.9985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>primus</td>\n",
              "      <td>pos</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>0.6289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ab</td>\n",
              "      <td>pos</td>\n",
              "      <td>ADP</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>oris</td>\n",
              "      <td>pos</td>\n",
              "      <td>NOUN</td>\n",
              "      <td>0.9981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>pos</td>\n",
              "      <td>PUNCT</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      token label_type    pos   score\n",
              "0      Arma        pos   NOUN  0.5548\n",
              "1  virumque        pos  PROPN  0.9616\n",
              "2      cano        pos   NOUN  0.4905\n",
              "3         ,        pos  PUNCT  1.0000\n",
              "4    Troiae        pos  PROPN  0.9718\n",
              "5       qui        pos   PRON  0.9985\n",
              "6    primus        pos   NOUN  0.6289\n",
              "7        ab        pos    ADP  1.0000\n",
              "8      oris        pos   NOUN  0.9981\n",
              "9         .        pos  PUNCT  1.0000"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_pos(token):\n",
        "    # model specifically uses \"pos\"\n",
        "    for label_type in (\"pos\"):\n",
        "        label = token.get_label(label_type)\n",
        "        \n",
        "        if label and label.value and label.value != \"O\":\n",
        "            return label_type, label.value, float(label.score)\n",
        "    \n",
        "    primary_label = token.get_label(tagger.label_type)\n",
        "    if primary_label:\n",
        "        return tagger.label_type, primary_label.value, float(primary_label.score)\n",
        "        \n",
        "    return \"\", \"\", 0.0\n",
        "\n",
        "sent = Sentence(example_text)\n",
        "tagger.predict(sent)\n",
        "\n",
        "rows = []\n",
        "for tok in sent:\n",
        "    label_type, value, score = get_pos(tok)\n",
        "    rows.append({\n",
        "        \"token\": tok.text, \n",
        "        \"label_type\": label_type, \n",
        "        \"pos\": value, \n",
        "        \"score\": round(score, 4)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2d0f5b0dfe54c7d",
      "metadata": {},
      "source": [
        "## 6) POS-tag multiple texts efficiently (mini-batching)\n",
        "This is the typical pattern for processing a corpus.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d8f1bba0a54191",
      "metadata": {},
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"In nomine sanctae et individuae trinitatis .\",\n",
        "    \"Quod infames uocentur qui ex consanguineis nascuntur .\",\n",
        "    \"Si quis clericus furtum fecerit , deponatur .\",\n",
        "]\n",
        "\n",
        "sentences = [Sentence(t) for t in texts]\n",
        "\n",
        "# mini_batch_size can be increased if you have enough VRAM\n",
        "tagger.predict(sentences, mini_batch_size=16)\n",
        "\n",
        "all_rows = []\n",
        "for i, s in enumerate(sentences):\n",
        "    for j, tok in enumerate(s):\n",
        "        label_type, value, score = get_pos(tok)\n",
        "        all_rows.append({\n",
        "            \"doc_id\": i,\n",
        "            \"token_id\": j,\n",
        "            \"token\": tok.text,\n",
        "            \"label_type\": label_type,\n",
        "            \"pos\": value,\n",
        "            \"score\": score,\n",
        "        })\n",
        "\n",
        "df_all = pd.DataFrame(all_rows)\n",
        "df_all.head(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4f74bfa0c524b29",
      "metadata": {},
      "source": [
        "## 7) Export as CoNLL-style text (optional)\n",
        "Useful if you want to feed the output into evaluation scripts or your own downstream pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e6cb4dca4d41c7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_conll(sentences):\n",
        "    lines = []\n",
        "    for doc_id, s in enumerate(sentences):\n",
        "        for tok in s:\n",
        "            _, pos, _ = get_pos(tok)\n",
        "            lines.append(f\"{tok.text}\\t{pos}\")\n",
        "        lines.append(\"\")  # sentence boundary\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(to_conll(sentences)[:1000])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv-jupyter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
