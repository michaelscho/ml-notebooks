{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# POS tagging Latin with Flair contextual string embeddings (legal) + trained tagger\n",
        "\n",
        "This notebook shows how to use:\n",
        "\n",
        "- Contextual string embeddings (Flair LM):\n",
        "  - `mschonhardt/latin-legal-forward`\n",
        "  - `mschonhardt/latin-legal-backward`\n",
        "- POS tagger trained on top of those embeddings:\n",
        "  - `mschonhardt/latin-pos-tagger`\n",
        "\n",
        "Key point: for POS tagging you usually only need to load the **tagger** (`SequenceTagger.load(...)`), because it already contains/uses its base embeddings. Loading the two LM embeddings separately is still useful if you want to (a) inspect/verify embeddings, or (b) reuse them for other downstream tasks.\n"
      ],
      "id": "a1e5f3a4c0b74252"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# If needed, install dependencies\n",
        "# !pip install -U flair torch pandas\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b3e7c8b0e8c14c6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Setup\n",
        "Select device, import libraries.\n"
      ],
      "id": "b67c9d51f6d74203"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import flair\n",
        "\n",
        "from flair.data import Sentence\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# Device selection\n",
        "flair.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"flair.device =\", flair.device)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "0b0e2f2a10f44b9d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Load your legal Latin Flair embeddings and stack them\n",
        "This is the canonical bidirectional setup (forward + backward) for downstream sequence tagging.\n"
      ],
      "id": "c72ee7a8ad8a4f3b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "LEGAL_FORWARD = \"mschonhardt/latin-legal-forward\"\n",
        "LEGAL_BACKWARD = \"mschonhardt/latin-legal-backward\"\n",
        "\n",
        "forward_embeddings = FlairEmbeddings(LEGAL_FORWARD)\n",
        "backward_embeddings = FlairEmbeddings(LEGAL_BACKWARD)\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings([forward_embeddings, backward_embeddings])\n",
        "print(stacked_embeddings)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9e2d42b5f5d34b93"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) (Optional) Embed a sentence to verify embeddings work\n",
        "This does *not* do POS tagging yet; it just computes contextual embeddings for each token.\n"
      ],
      "id": "a5e0bba2d3f94c0a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "example_text = \"In nomine sanctae et individuae trinitatis .\"\n",
        "sent = Sentence(example_text)\n",
        "\n",
        "stacked_embeddings.embed(sent)\n",
        "\n",
        "# Each token now has an embedding vector. We'll print token texts + embedding dimensionality.\n",
        "for token in sent:\n",
        "    emb = token.embedding\n",
        "    print(token.text, \"\\t\", emb.shape)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "e0b2f4d7e4524f36"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Load your POS tagger (trained on those embeddings)\n",
        "For POS tagging, this is usually all you need.\n"
      ],
      "id": "d2f7c80e2c1b4a7b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "POS_TAGGER_ID = \"mschonhardt/latin-pos-tagger\"\n",
        "tagger = SequenceTagger.load(POS_TAGGER_ID)\n",
        "print(tagger)\n",
        "\n",
        "# Optional: inspect what embeddings are inside the tagger\n",
        "try:\n",
        "    print(\"\\nTagger embeddings:\")\n",
        "    print(tagger.embeddings)\n",
        "except Exception as e:\n",
        "    print(\"Could not print tagger.embeddings:\", e)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "b0bb4dd62c124ca7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) POS-tag a single sentence\n",
        "Your model card suggests reading tags from `upos`.\n",
        "Weâ€™ll implement a small helper that tries `upos` first, then falls back to `pos`.\n"
      ],
      "id": "d95f7c1a2b5d45da"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def get_pos(token):\n",
        "    # Prefer UPOS (as in your model card), fall back to POS.\n",
        "    for label_type in (\"upos\", \"pos\"):\n",
        "        try:\n",
        "            t = token.get_tag(label_type)\n",
        "            if t is not None and getattr(t, \"value\", None):\n",
        "                return label_type, t.value, float(getattr(t, \"score\", 0.0))\n",
        "        except Exception:\n",
        "            pass\n",
        "    return \"\", \"\", 0.0\n",
        "\n",
        "sent = Sentence(example_text)\n",
        "tagger.predict(sent)\n",
        "\n",
        "rows = []\n",
        "for tok in sent:\n",
        "    label_type, value, score = get_pos(tok)\n",
        "    rows.append({\"token\": tok.text, \"label_type\": label_type, \"pos\": value, \"score\": score})\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "bf2b0c727c3f4e86"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) POS-tag multiple texts efficiently (mini-batching)\n",
        "This is the typical pattern for processing a corpus.\n"
      ],
      "id": "a2d0f5b0dfe54c7d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "texts = [\n",
        "    \"In nomine sanctae et individuae trinitatis .\",\n",
        "    \"Quod infames uocentur qui ex consanguineis nascuntur .\",\n",
        "    \"Si quis clericus furtum fecerit , deponatur .\",\n",
        "]\n",
        "\n",
        "sentences = [Sentence(t) for t in texts]\n",
        "\n",
        "# mini_batch_size can be increased if you have enough VRAM\n",
        "tagger.predict(sentences, mini_batch_size=16)\n",
        "\n",
        "all_rows = []\n",
        "for i, s in enumerate(sentences):\n",
        "    for j, tok in enumerate(s):\n",
        "        label_type, value, score = get_pos(tok)\n",
        "        all_rows.append({\n",
        "            \"doc_id\": i,\n",
        "            \"token_id\": j,\n",
        "            \"token\": tok.text,\n",
        "            \"label_type\": label_type,\n",
        "            \"pos\": value,\n",
        "            \"score\": score,\n",
        "        })\n",
        "\n",
        "df_all = pd.DataFrame(all_rows)\n",
        "df_all.head(30)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a6d8f1bba0a54191"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Export as CoNLL-style text (optional)\n",
        "Useful if you want to feed the output into evaluation scripts or your own downstream pipeline.\n"
      ],
      "id": "d4f74bfa0c524b29"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def to_conll(sentences):\n",
        "    lines = []\n",
        "    for doc_id, s in enumerate(sentences):\n",
        "        for tok in s:\n",
        "            _, pos, _ = get_pos(tok)\n",
        "            lines.append(f\"{tok.text}\\t{pos}\")\n",
        "        lines.append(\"\")  # sentence boundary\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(to_conll(sentences)[:1000])\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f0e6cb4dca4d41c7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "nbconvert_exporter": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
